{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d58bd2147497bfa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21bdef681a4acd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5269dd170938718d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "25117dfcdaf520fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe915502b961fcf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb591ad2a7457d92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9ef7c1d5816668"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8402cd3ea6b182a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f6ff6f33206715fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38646f284bbe0301"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91c904cc9c993af8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdd0d9f9e89a274",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:29.025519Z",
     "start_time": "2023-11-06T17:28:25.326436Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45b6f43b2f2931c"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# CHECK BEFORE RUNNING!!!\n",
    "flag_preprocess = False # If false, skip the generation of a preprocessed corpus\n",
    "flag_cluster_labels = False \n",
    "flag_cluster = False # If false, stop overwrite of a cluster matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T16:12:38.422161Z",
     "start_time": "2023-11-07T16:12:38.222534Z"
    }
   },
   "id": "dd37d16e1f625a5f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define column names for movie.metadata.tsv\n",
    "movie_metadata_columns = [\"Wikipedia Movie ID\", \"Freebase Movie ID\", \"Movie name\", \"Movie release date\",\n",
    "                          \"Movie box office revenue\", \"Movie runtime\", \"Movie languages\", \"Movie countries\",\n",
    "                          \"Movie genres\"]\n",
    "\n",
    "# Read movie.metadata.tsv into a DataFrame\n",
    "movie_metadata_df = pd.read_csv(\"data/movie.metadata.tsv\", sep='\\t', header=None, names=movie_metadata_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:32.804694Z",
     "start_time": "2023-11-06T17:28:32.384608Z"
    }
   },
   "id": "d135c63f2f59940a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mathiaskroismoller/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mathiaskroismoller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    # Convert to lowercase and tokenize\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Assuming your movie plot summaries are stored in 'summaries.txt'\n",
    "with open('data/plot_summaries.txt', 'r', encoding='utf-8') as file:\n",
    "    summaries = file.readlines()\n",
    "\n",
    "# Extract movie IDs \n",
    "movie_ids = [int(summary.split()[0]) for summary in summaries]\n",
    "\n",
    "# Preprocess the summaries with a progress bar\n",
    "preprocessed_summaries = []\n",
    "if flag_preprocess:\n",
    "    for summary in tqdm(summaries, desc=\"Processing summaries\"):\n",
    "        preprocessed_summaries.append(preprocess_text(summary.split('\\t')[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:36.293482Z",
     "start_time": "2023-11-06T17:28:33.574171Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Save preprocessed summaries to a pkl file\n",
    "import csv\n",
    "if flag_preprocess:\n",
    "    # Save preprocessed_summaries list to a file\n",
    "    with open('preprocessed_summaries.pkl', 'wb') as file:\n",
    "        pickle.dump(preprocessed_summaries, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:38.248747Z",
     "start_time": "2023-11-06T17:28:38.209321Z"
    }
   },
   "id": "d70280c4bbcfe17"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Combined stemmed summaries with labels \n",
    "summaries_dist = []\n",
    "if flag_preprocess:\n",
    "    for i in range(len(preprocessed_summaries)):\n",
    "        summaries_dist.append({\"label\": movie_ids[i], \"text\": preprocessed_summaries[i]})\n",
    "    \n",
    "    # Save summaries_dist to a JSON file\n",
    "    with open('summaries_dist.json', 'w') as f:\n",
    "        json.dump(summaries_dist, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:39.158115Z",
     "start_time": "2023-11-06T17:28:39.126012Z"
    }
   },
   "id": "bbca78b926507c70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Home made version TF/IDF vectorization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c2818cdebf047"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Load preprocessed_summaries list from the saved file\n",
    "with open('preprocessed_summaries.pkl', 'rb') as file:\n",
    "    preprocessed_summaries = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:50.030479Z",
     "start_time": "2023-11-06T17:28:49.738404Z"
    }
   },
   "id": "7224696ad5a9625f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Convert text data into numerical features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_summaries)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:29:00.873846Z",
     "start_time": "2023-11-06T17:28:53.174567Z"
    }
   },
   "id": "48432b3e10fdfcee"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Apply KMeans clustering\n",
    "if flag_cluster_labels:\n",
    "    num_clusters = 100  # You can adjust the number of clusters as needed\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "    \n",
    "    # Save cluster_labels to a file\n",
    "    with open('cluster_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(cluster_labels, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:00:41.223036Z",
     "start_time": "2023-11-06T17:29:15.896575Z"
    }
   },
   "id": "9677733f4d61f5d9"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Load cluster_labels from a file\n",
    "with open('cluster_labels.pkl', 'rb') as f:\n",
    "    cluster_labels = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:56:05.045989Z",
     "start_time": "2023-11-06T18:56:04.975355Z"
    }
   },
   "id": "95def09953470139"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary to store movie IDs and their corresponding cluster labels\n",
    "movie_clusters = dict(zip(movie_ids, cluster_labels))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ddaa5a5d1cdda8"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42306/42306 [18:24<00:00, 38.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store cluster information\n",
    "cluster_df = pd.DataFrame(columns=[f'Cluster {i}' for i in range(num_clusters)])\n",
    "\n",
    "# Iterate through movie clusters and match with movie_metadata_df\n",
    "if flag_cluster:\n",
    "    for movie_id, cluster_label in tqdm(movie_clusters.items()):\n",
    "        # Find the corresponding row in movie_metadata_df based on Wikipedia Movie ID\n",
    "        movie_row = movie_metadata_df[movie_metadata_df['Wikipedia Movie ID'] == movie_id]\n",
    "        \n",
    "        # Extract movie name from the row\n",
    "        movie_name = movie_row['Movie name'].values[0] if not movie_row.empty else f'Movie {movie_id}'\n",
    "        \n",
    "        # Update cluster_df with movie name in the appropriate cluster column\n",
    "        cluster_df.loc[len(cluster_df), f'Cluster {cluster_label}'] = movie_name\n",
    "    \n",
    "    \n",
    "    # Fill NaN values with empty string for better representation\n",
    "    cluster_df.fillna('', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:47.483252Z",
     "start_time": "2023-11-07T16:46:21.338396Z"
    }
   },
   "id": "f62ba84723dfac33"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# Save cluster_df as CSV\n",
    "if flag_cluster:\n",
    "    cluster_df.to_csv('clustered_movies.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:48.429661Z",
     "start_time": "2023-11-07T17:04:47.513258Z"
    }
   },
   "id": "595156f2c8eb5278"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/tvll5hmx5b580xjtn0kmrff00000gn/T/ipykernel_5219/1653686429.py:2: DtypeWarning: Columns (31,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cluster_df = pd.read_csv('clustered_movies.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load cluster_df from a file\n",
    "cluster_df = pd.read_csv('clustered_movies.csv')\n",
    "\n",
    "def transform_dataframe(df):\n",
    "    # Replace NaN values with np.nan (optional if you want to keep np.nan instead of removing them)\n",
    "    df = df.replace(np.nan, pd.NA)\n",
    "    \n",
    "    # Drop columns with NaN values\n",
    "    df_cleaned = df.dropna(axis=1)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "cluster_df = transform_dataframe(cluster_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:28:50.607925Z",
     "start_time": "2023-11-07T17:28:49.935114Z"
    }
   },
   "id": "443afcac549ed2aa"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Save cluster_df as CSV\n",
    "if flag_cluster:\n",
    "    cluster_df.to_csv('clustered_movies_test.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:26:51.282788Z",
     "start_time": "2023-11-07T17:26:51.134765Z"
    }
   },
   "id": "c498e85ee873c95e"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/tvll5hmx5b580xjtn0kmrff00000gn/T/ipykernel_5219/4017522519.py:2: DtypeWarning: Columns (31,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cluster_df = pd.read_csv('clustered_movies.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load cluster_df from a file\n",
    "cluster_df = pd.read_csv('clustered_movies.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:50.297616Z",
     "start_time": "2023-11-07T17:04:49.646818Z"
    }
   },
   "id": "c6d4f84dbd7e9493"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Top 10 words pr cluster"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3592a009517e4f14"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def get_top_words_for_clusters(tfidf_matrix, cluster_labels, vectorizer, top_n=10):\n",
    "    cluster_words = {}\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    for cluster_label in range(max(cluster_labels) + 1):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        cluster_tfidf_scores = np.sum(tfidf_matrix[cluster_indices], axis=0)\n",
    "        sorted_indices = np.argsort(cluster_tfidf_scores)[0, ::-1][:top_n]\n",
    "        top_words = [terms[i] for i in sorted_indices]\n",
    "        cluster_words[cluster_label] = top_words\n",
    "        \n",
    "    return cluster_words\n",
    "\n",
    "# Call the function to get cluster words\n",
    "cluster_words = get_top_words_for_clusters(tfidf_matrix, cluster_labels, vectorizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9480f3fbe8cc48b6"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['peter', 'love', 'man', 'wendy', 'spider', 'father', 'jack',\n       'back', 'home', 'one'], dtype=object)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_words[0][0][0][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:48:10.558176Z",
     "start_time": "2023-11-07T15:48:10.379355Z"
    }
   },
   "id": "c4e31bc29d96ba7"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "           0       1            2          3            4         5  \\\n0      peter   jesse         raju     school        henry      cite   \n1       love   james        karan   students         anne       web   \n2        man   willy         amar       high    catherine  synopsis   \n3      wendy   ethan        vicky    teacher          sir      film   \n4     spider  celine         love    student       family     based   \n..       ...     ...          ...        ...          ...       ...   \n995    staff  moving         sell       yuko  shakespeare   classic   \n996    lomax   radio         koya       post      accepts       sik   \n997  mcnally    pull  millionaire  reluctant    befriends  murderer   \n998    nurse  shadow     microdot      naomi      realize     train   \n999     date  inform        hates       kyle       summer      body   \n\n              6        7        8           9  ...      90          91  \\\n0         agent     bill      one        love  ...   vijay         jim   \n1     president      new   police       falls  ...    love      silver   \n2        united     life      two    marriage  ...    ravi      father   \n3        states   connie     life        girl  ...   kumar         new   \n4        soviet     film      new    daughter  ...  father     stifler   \n..          ...      ...      ...         ...  ...     ...         ...   \n995       opens     ever    youth  aristocrat  ...   birth         cop   \n996  especially  honesty     pass       satya  ...  indeed         eye   \n997     married   goldie  program     present  ...  motley  protecting   \n998  interviews   jackie   miller    american  ...   kallu    suddenly   \n999        tech    roper    woods     approve  ...  visits      person   \n\n           92            93         94         95         96          97  \\\n0     charles          joan        man  sylvester      harry      martin   \n1       katie        joseph      young     tweety        one      police   \n2      edward          jack        old        cat  voldemort        wife   \n3       bella          life        one     granny        two      family   \n4         sir        father       wife     speedy        man   blomkvist   \n..        ...           ...        ...        ...        ...         ...   \n995  ceremony     encounter    jealous   vacation       feet       words   \n996   quickly        famine       dave    exhibit         pc    engineer   \n997  neighbor        dinner     action    holding   elevator      sexual   \n998    health  bloodthirsty      stage    mission     states  highwaymen   \n999  property    uncredited  amusement    hearing     cedric       thief   \n\n            98            99  \n0          bob      creature  \n1        larry       monster  \n2        kevin      godzilla  \n3         song  frankenstein  \n4      however        dragon  \n..         ...           ...  \n995  detective         close  \n996       tree          cold  \n997     search        liquid  \n998        rob       weapons  \n999        bar           joe  \n\n[1000 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>peter</td>\n      <td>jesse</td>\n      <td>raju</td>\n      <td>school</td>\n      <td>henry</td>\n      <td>cite</td>\n      <td>agent</td>\n      <td>bill</td>\n      <td>one</td>\n      <td>love</td>\n      <td>...</td>\n      <td>vijay</td>\n      <td>jim</td>\n      <td>charles</td>\n      <td>joan</td>\n      <td>man</td>\n      <td>sylvester</td>\n      <td>harry</td>\n      <td>martin</td>\n      <td>bob</td>\n      <td>creature</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>love</td>\n      <td>james</td>\n      <td>karan</td>\n      <td>students</td>\n      <td>anne</td>\n      <td>web</td>\n      <td>president</td>\n      <td>new</td>\n      <td>police</td>\n      <td>falls</td>\n      <td>...</td>\n      <td>love</td>\n      <td>silver</td>\n      <td>katie</td>\n      <td>joseph</td>\n      <td>young</td>\n      <td>tweety</td>\n      <td>one</td>\n      <td>police</td>\n      <td>larry</td>\n      <td>monster</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man</td>\n      <td>willy</td>\n      <td>amar</td>\n      <td>high</td>\n      <td>catherine</td>\n      <td>synopsis</td>\n      <td>united</td>\n      <td>life</td>\n      <td>two</td>\n      <td>marriage</td>\n      <td>...</td>\n      <td>ravi</td>\n      <td>father</td>\n      <td>edward</td>\n      <td>jack</td>\n      <td>old</td>\n      <td>cat</td>\n      <td>voldemort</td>\n      <td>wife</td>\n      <td>kevin</td>\n      <td>godzilla</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wendy</td>\n      <td>ethan</td>\n      <td>vicky</td>\n      <td>teacher</td>\n      <td>sir</td>\n      <td>film</td>\n      <td>states</td>\n      <td>connie</td>\n      <td>life</td>\n      <td>girl</td>\n      <td>...</td>\n      <td>kumar</td>\n      <td>new</td>\n      <td>bella</td>\n      <td>life</td>\n      <td>one</td>\n      <td>granny</td>\n      <td>two</td>\n      <td>family</td>\n      <td>song</td>\n      <td>frankenstein</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>spider</td>\n      <td>celine</td>\n      <td>love</td>\n      <td>student</td>\n      <td>family</td>\n      <td>based</td>\n      <td>soviet</td>\n      <td>film</td>\n      <td>new</td>\n      <td>daughter</td>\n      <td>...</td>\n      <td>father</td>\n      <td>stifler</td>\n      <td>sir</td>\n      <td>father</td>\n      <td>wife</td>\n      <td>speedy</td>\n      <td>man</td>\n      <td>blomkvist</td>\n      <td>however</td>\n      <td>dragon</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>staff</td>\n      <td>moving</td>\n      <td>sell</td>\n      <td>yuko</td>\n      <td>shakespeare</td>\n      <td>classic</td>\n      <td>opens</td>\n      <td>ever</td>\n      <td>youth</td>\n      <td>aristocrat</td>\n      <td>...</td>\n      <td>birth</td>\n      <td>cop</td>\n      <td>ceremony</td>\n      <td>encounter</td>\n      <td>jealous</td>\n      <td>vacation</td>\n      <td>feet</td>\n      <td>words</td>\n      <td>detective</td>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>lomax</td>\n      <td>radio</td>\n      <td>koya</td>\n      <td>post</td>\n      <td>accepts</td>\n      <td>sik</td>\n      <td>especially</td>\n      <td>honesty</td>\n      <td>pass</td>\n      <td>satya</td>\n      <td>...</td>\n      <td>indeed</td>\n      <td>eye</td>\n      <td>quickly</td>\n      <td>famine</td>\n      <td>dave</td>\n      <td>exhibit</td>\n      <td>pc</td>\n      <td>engineer</td>\n      <td>tree</td>\n      <td>cold</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>mcnally</td>\n      <td>pull</td>\n      <td>millionaire</td>\n      <td>reluctant</td>\n      <td>befriends</td>\n      <td>murderer</td>\n      <td>married</td>\n      <td>goldie</td>\n      <td>program</td>\n      <td>present</td>\n      <td>...</td>\n      <td>motley</td>\n      <td>protecting</td>\n      <td>neighbor</td>\n      <td>dinner</td>\n      <td>action</td>\n      <td>holding</td>\n      <td>elevator</td>\n      <td>sexual</td>\n      <td>search</td>\n      <td>liquid</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>nurse</td>\n      <td>shadow</td>\n      <td>microdot</td>\n      <td>naomi</td>\n      <td>realize</td>\n      <td>train</td>\n      <td>interviews</td>\n      <td>jackie</td>\n      <td>miller</td>\n      <td>american</td>\n      <td>...</td>\n      <td>kallu</td>\n      <td>suddenly</td>\n      <td>health</td>\n      <td>bloodthirsty</td>\n      <td>stage</td>\n      <td>mission</td>\n      <td>states</td>\n      <td>highwaymen</td>\n      <td>rob</td>\n      <td>weapons</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>date</td>\n      <td>inform</td>\n      <td>hates</td>\n      <td>kyle</td>\n      <td>summer</td>\n      <td>body</td>\n      <td>tech</td>\n      <td>roper</td>\n      <td>woods</td>\n      <td>approve</td>\n      <td>...</td>\n      <td>visits</td>\n      <td>person</td>\n      <td>property</td>\n      <td>uncredited</td>\n      <td>amusement</td>\n      <td>hearing</td>\n      <td>cedric</td>\n      <td>thief</td>\n      <td>bar</td>\n      <td>joe</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for top 1000 words ranked for every cluster\n",
    "cluster_words_ranked = pd.DataFrame()\n",
    "\n",
    "for i in range(len(cluster_words)):\n",
    "    cluster_words_ranked[f'{i}'] = cluster_words[i][0][0][:1000]\n",
    "    \n",
    "cluster_words_ranked"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:59:31.812204Z",
     "start_time": "2023-11-07T15:59:31.600599Z"
    }
   },
   "id": "a41d7d837d72e0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "cluster_words_ranked.to_csv('cluster_words.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:59:34.064003Z",
     "start_time": "2023-11-07T15:59:33.996034Z"
    }
   },
   "id": "56bbdec4dab76738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NPL version (Nothing yet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "157e33cc2b984c4a"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Load summaries_dist from a JSON file\n",
    "with open('summaries_dist.json', 'r') as f:\n",
    "    summaries_dist = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:11:39.091150Z",
     "start_time": "2023-11-06T16:11:38.911288Z"
    }
   },
   "id": "e50c55d094624b6c"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T15:50:38.847465Z",
     "start_time": "2023-11-06T15:50:38.263592Z"
    }
   },
   "id": "10b04b346fe708ad"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T15:51:12.353947Z",
     "start_time": "2023-11-06T15:51:12.322750Z"
    }
   },
   "id": "7b8fa341c2ad36bb"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[86], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenized_sum \u001B[38;5;241m=\u001B[39m \u001B[43msummaries_dist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m(preprocess_function, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "tokenized_sum = summaries_dist.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:12:47.846330Z",
     "start_time": "2023-11-06T16:12:47.610183Z"
    }
   },
   "id": "c2f8516f8486b447"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2a68eabba0f92"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
