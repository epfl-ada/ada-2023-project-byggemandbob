{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdd0d9f9e89a274",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:29.025519Z",
     "start_time": "2023-11-06T17:28:25.326436Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45b6f43b2f2931c"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# CHECK BEFORE RUNNING!!!\n",
    "flag_preprocess = False # If false, skip the generation of a preprocessed corpus\n",
    "flag_cluster_labels = False \n",
    "flag_cluster = False # If false, stop overwrite of a cluster matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:22:03.764512Z",
     "start_time": "2023-11-08T11:22:03.742551Z"
    }
   },
   "id": "dd37d16e1f625a5f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define column names for movie.metadata.tsv\n",
    "movie_metadata_columns = [\"Wikipedia Movie ID\", \"Freebase Movie ID\", \"Movie name\", \"Movie release date\",\n",
    "                          \"Movie box office revenue\", \"Movie runtime\", \"Movie languages\", \"Movie countries\",\n",
    "                          \"Movie genres\"]\n",
    "\n",
    "# Read movie.metadata.tsv into a DataFrame\n",
    "movie_metadata_df = pd.read_csv(\"data/movie.metadata.tsv\", sep='\\t', header=None, names=movie_metadata_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:32.804694Z",
     "start_time": "2023-11-06T17:28:32.384608Z"
    }
   },
   "id": "d135c63f2f59940a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mathiaskroismoller/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mathiaskroismoller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    # Convert to lowercase and tokenize\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Open 'plot_summaries.txt'\n",
    "with open('data/plot_summaries.txt', 'r', encoding='utf-8') as file:\n",
    "    summaries = file.readlines()\n",
    "\n",
    "# Extract movie IDs \n",
    "movie_ids = [int(summary.split()[0]) for summary in summaries]\n",
    "\n",
    "# Preprocess the summaries \n",
    "preprocessed_summaries = []\n",
    "if flag_preprocess:\n",
    "    for summary in tqdm(summaries, desc=\"Processing summaries\"):\n",
    "        preprocessed_summaries.append(preprocess_text(summary.split('\\t')[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:36.293482Z",
     "start_time": "2023-11-06T17:28:33.574171Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Save preprocessed summaries to a pkl file\n",
    "import csv\n",
    "if flag_preprocess:\n",
    "    # Save preprocessed_summaries list to a file\n",
    "    with open('preprocessed_summaries.pkl', 'wb') as file:\n",
    "        pickle.dump(preprocessed_summaries, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:38.248747Z",
     "start_time": "2023-11-06T17:28:38.209321Z"
    }
   },
   "id": "d70280c4bbcfe17"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Combined stemmed summaries with labels \n",
    "summaries_preprocessed_dist = []\n",
    "if flag_preprocess:\n",
    "    for i in range(len(preprocessed_summaries)):\n",
    "        summaries_preprocessed_dist.append({\"id\": movie_ids[i], \"text\": preprocessed_summaries[i]})\n",
    "    \n",
    "    # Save summaries_preprocessed_dist to a JSON file\n",
    "    with open('summaries_preprocessed_dist.json', 'w') as f:\n",
    "        json.dump(summaries_preprocessed_dist, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:39.158115Z",
     "start_time": "2023-11-06T17:28:39.126012Z"
    }
   },
   "id": "bbca78b926507c70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Home made version TF/IDF vectorization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c2818cdebf047"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Load preprocessed_summaries list from the saved file\n",
    "with open('preprocessed_summaries.pkl', 'rb') as file:\n",
    "    preprocessed_summaries = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:28:50.030479Z",
     "start_time": "2023-11-06T17:28:49.738404Z"
    }
   },
   "id": "7224696ad5a9625f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Convert text data into numerical features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_summaries)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T17:29:00.873846Z",
     "start_time": "2023-11-06T17:28:53.174567Z"
    }
   },
   "id": "48432b3e10fdfcee"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Apply KMeans clustering\n",
    "if flag_cluster_labels:\n",
    "    num_clusters = 100  # You can adjust the number of clusters -> the more clusters the heavier the computation\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tfidf_matrix) # This takes a loooong time...\n",
    "    \n",
    "    # Save cluster_labels to a file\n",
    "    with open('cluster_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(cluster_labels, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:00:41.223036Z",
     "start_time": "2023-11-06T17:29:15.896575Z"
    }
   },
   "id": "9677733f4d61f5d9"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Load cluster_labels from a file\n",
    "with open('cluster_labels.pkl', 'rb') as f:\n",
    "    cluster_labels = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T18:56:05.045989Z",
     "start_time": "2023-11-06T18:56:04.975355Z"
    }
   },
   "id": "95def09953470139"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "# Create a dictionary to store movie IDs and their corresponding cluster labels\n",
    "movie_clusters = dict(zip(movie_ids, cluster_labels))\n",
    "\n",
    "# Save the dictionary to a file using pickle\n",
    "with open('movie_clusters_id.pkl', 'wb') as file:\n",
    "    pickle.dump(movie_clusters, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T10:58:58.297654Z",
     "start_time": "2023-11-08T10:58:58.101458Z"
    }
   },
   "id": "35ddaa5a5d1cdda8"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42306/42306 [20:07<00:00, 35.04it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store cluster information\n",
    "cluster_df = pd.DataFrame(columns=[f'Cluster {i}' for i in range(num_clusters)])\n",
    "\n",
    "# Iterate through movie clusters and match with movie_metadata_df\n",
    "if flag_cluster:\n",
    "    for movie_id, cluster_label in tqdm(movie_clusters.items()):\n",
    "        # Find the corresponding row in movie_metadata_df based on Wikipedia Movie ID\n",
    "        movie_row = movie_metadata_df[movie_metadata_df['Wikipedia Movie ID'] == movie_id]\n",
    "        \n",
    "        # Extract movie name from the row\n",
    "        movie_name = movie_row['Movie name'].values[0] if not movie_row.empty else f'Movie {movie_id}'\n",
    "        \n",
    "        # Update cluster_df with movie name in the appropriate cluster column\n",
    "        cluster_df.loc[len(cluster_df), f'Cluster {cluster_label}'] = movie_name\n",
    "    \n",
    "    \n",
    "    # Fill NaN values with empty string for better representation\n",
    "    cluster_df.fillna('', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:19:19.984244Z",
     "start_time": "2023-11-08T10:59:10.161009Z"
    }
   },
   "id": "f62ba84723dfac33"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# Save cluster_df as CSV\n",
    "if flag_cluster:\n",
    "    cluster_df.to_csv('clustered_movies.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:21:21.119975Z",
     "start_time": "2023-11-08T11:21:19.152167Z"
    }
   },
   "id": "595156f2c8eb5278"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/tvll5hmx5b580xjtn0kmrff00000gn/T/ipykernel_5219/4017522519.py:2: DtypeWarning: Columns (31,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cluster_df = pd.read_csv('clustered_movies.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load cluster_df from a file\n",
    "cluster_df = pd.read_csv('clustered_movies.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:50.297616Z",
     "start_time": "2023-11-07T17:04:49.646818Z"
    }
   },
   "id": "c6d4f84dbd7e9493"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Top 10 words pr cluster"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3592a009517e4f14"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def get_top_words_for_clusters(tfidf_matrix, cluster_labels, vectorizer, top_n=10):\n",
    "    cluster_words = {}\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    for cluster_label in range(max(cluster_labels) + 1):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
    "        cluster_tfidf_scores = np.sum(tfidf_matrix[cluster_indices], axis=0)\n",
    "        sorted_indices = np.argsort(cluster_tfidf_scores)[0, ::-1][:top_n]\n",
    "        top_words = [terms[i] for i in sorted_indices]\n",
    "        cluster_words[cluster_label] = top_words\n",
    "        \n",
    "    return cluster_words\n",
    "\n",
    "# Call the function to get cluster words\n",
    "cluster_words = get_top_words_for_clusters(tfidf_matrix, cluster_labels, vectorizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9480f3fbe8cc48b6"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['peter', 'love', 'man', 'wendy', 'spider', 'father', 'jack',\n       'back', 'home', 'one'], dtype=object)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_words[0][0][0][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:48:10.558176Z",
     "start_time": "2023-11-07T15:48:10.379355Z"
    }
   },
   "id": "c4e31bc29d96ba7"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "           0       1            2          3            4         5  \\\n0      peter   jesse         raju     school        henry      cite   \n1       love   james        karan   students         anne       web   \n2        man   willy         amar       high    catherine  synopsis   \n3      wendy   ethan        vicky    teacher          sir      film   \n4     spider  celine         love    student       family     based   \n..       ...     ...          ...        ...          ...       ...   \n995    staff  moving         sell       yuko  shakespeare   classic   \n996    lomax   radio         koya       post      accepts       sik   \n997  mcnally    pull  millionaire  reluctant    befriends  murderer   \n998    nurse  shadow     microdot      naomi      realize     train   \n999     date  inform        hates       kyle       summer      body   \n\n              6        7        8           9  ...      90          91  \\\n0         agent     bill      one        love  ...   vijay         jim   \n1     president      new   police       falls  ...    love      silver   \n2        united     life      two    marriage  ...    ravi      father   \n3        states   connie     life        girl  ...   kumar         new   \n4        soviet     film      new    daughter  ...  father     stifler   \n..          ...      ...      ...         ...  ...     ...         ...   \n995       opens     ever    youth  aristocrat  ...   birth         cop   \n996  especially  honesty     pass       satya  ...  indeed         eye   \n997     married   goldie  program     present  ...  motley  protecting   \n998  interviews   jackie   miller    american  ...   kallu    suddenly   \n999        tech    roper    woods     approve  ...  visits      person   \n\n           92            93         94         95         96          97  \\\n0     charles          joan        man  sylvester      harry      martin   \n1       katie        joseph      young     tweety        one      police   \n2      edward          jack        old        cat  voldemort        wife   \n3       bella          life        one     granny        two      family   \n4         sir        father       wife     speedy        man   blomkvist   \n..        ...           ...        ...        ...        ...         ...   \n995  ceremony     encounter    jealous   vacation       feet       words   \n996   quickly        famine       dave    exhibit         pc    engineer   \n997  neighbor        dinner     action    holding   elevator      sexual   \n998    health  bloodthirsty      stage    mission     states  highwaymen   \n999  property    uncredited  amusement    hearing     cedric       thief   \n\n            98            99  \n0          bob      creature  \n1        larry       monster  \n2        kevin      godzilla  \n3         song  frankenstein  \n4      however        dragon  \n..         ...           ...  \n995  detective         close  \n996       tree          cold  \n997     search        liquid  \n998        rob       weapons  \n999        bar           joe  \n\n[1000 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>peter</td>\n      <td>jesse</td>\n      <td>raju</td>\n      <td>school</td>\n      <td>henry</td>\n      <td>cite</td>\n      <td>agent</td>\n      <td>bill</td>\n      <td>one</td>\n      <td>love</td>\n      <td>...</td>\n      <td>vijay</td>\n      <td>jim</td>\n      <td>charles</td>\n      <td>joan</td>\n      <td>man</td>\n      <td>sylvester</td>\n      <td>harry</td>\n      <td>martin</td>\n      <td>bob</td>\n      <td>creature</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>love</td>\n      <td>james</td>\n      <td>karan</td>\n      <td>students</td>\n      <td>anne</td>\n      <td>web</td>\n      <td>president</td>\n      <td>new</td>\n      <td>police</td>\n      <td>falls</td>\n      <td>...</td>\n      <td>love</td>\n      <td>silver</td>\n      <td>katie</td>\n      <td>joseph</td>\n      <td>young</td>\n      <td>tweety</td>\n      <td>one</td>\n      <td>police</td>\n      <td>larry</td>\n      <td>monster</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man</td>\n      <td>willy</td>\n      <td>amar</td>\n      <td>high</td>\n      <td>catherine</td>\n      <td>synopsis</td>\n      <td>united</td>\n      <td>life</td>\n      <td>two</td>\n      <td>marriage</td>\n      <td>...</td>\n      <td>ravi</td>\n      <td>father</td>\n      <td>edward</td>\n      <td>jack</td>\n      <td>old</td>\n      <td>cat</td>\n      <td>voldemort</td>\n      <td>wife</td>\n      <td>kevin</td>\n      <td>godzilla</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wendy</td>\n      <td>ethan</td>\n      <td>vicky</td>\n      <td>teacher</td>\n      <td>sir</td>\n      <td>film</td>\n      <td>states</td>\n      <td>connie</td>\n      <td>life</td>\n      <td>girl</td>\n      <td>...</td>\n      <td>kumar</td>\n      <td>new</td>\n      <td>bella</td>\n      <td>life</td>\n      <td>one</td>\n      <td>granny</td>\n      <td>two</td>\n      <td>family</td>\n      <td>song</td>\n      <td>frankenstein</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>spider</td>\n      <td>celine</td>\n      <td>love</td>\n      <td>student</td>\n      <td>family</td>\n      <td>based</td>\n      <td>soviet</td>\n      <td>film</td>\n      <td>new</td>\n      <td>daughter</td>\n      <td>...</td>\n      <td>father</td>\n      <td>stifler</td>\n      <td>sir</td>\n      <td>father</td>\n      <td>wife</td>\n      <td>speedy</td>\n      <td>man</td>\n      <td>blomkvist</td>\n      <td>however</td>\n      <td>dragon</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>staff</td>\n      <td>moving</td>\n      <td>sell</td>\n      <td>yuko</td>\n      <td>shakespeare</td>\n      <td>classic</td>\n      <td>opens</td>\n      <td>ever</td>\n      <td>youth</td>\n      <td>aristocrat</td>\n      <td>...</td>\n      <td>birth</td>\n      <td>cop</td>\n      <td>ceremony</td>\n      <td>encounter</td>\n      <td>jealous</td>\n      <td>vacation</td>\n      <td>feet</td>\n      <td>words</td>\n      <td>detective</td>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>lomax</td>\n      <td>radio</td>\n      <td>koya</td>\n      <td>post</td>\n      <td>accepts</td>\n      <td>sik</td>\n      <td>especially</td>\n      <td>honesty</td>\n      <td>pass</td>\n      <td>satya</td>\n      <td>...</td>\n      <td>indeed</td>\n      <td>eye</td>\n      <td>quickly</td>\n      <td>famine</td>\n      <td>dave</td>\n      <td>exhibit</td>\n      <td>pc</td>\n      <td>engineer</td>\n      <td>tree</td>\n      <td>cold</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>mcnally</td>\n      <td>pull</td>\n      <td>millionaire</td>\n      <td>reluctant</td>\n      <td>befriends</td>\n      <td>murderer</td>\n      <td>married</td>\n      <td>goldie</td>\n      <td>program</td>\n      <td>present</td>\n      <td>...</td>\n      <td>motley</td>\n      <td>protecting</td>\n      <td>neighbor</td>\n      <td>dinner</td>\n      <td>action</td>\n      <td>holding</td>\n      <td>elevator</td>\n      <td>sexual</td>\n      <td>search</td>\n      <td>liquid</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>nurse</td>\n      <td>shadow</td>\n      <td>microdot</td>\n      <td>naomi</td>\n      <td>realize</td>\n      <td>train</td>\n      <td>interviews</td>\n      <td>jackie</td>\n      <td>miller</td>\n      <td>american</td>\n      <td>...</td>\n      <td>kallu</td>\n      <td>suddenly</td>\n      <td>health</td>\n      <td>bloodthirsty</td>\n      <td>stage</td>\n      <td>mission</td>\n      <td>states</td>\n      <td>highwaymen</td>\n      <td>rob</td>\n      <td>weapons</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>date</td>\n      <td>inform</td>\n      <td>hates</td>\n      <td>kyle</td>\n      <td>summer</td>\n      <td>body</td>\n      <td>tech</td>\n      <td>roper</td>\n      <td>woods</td>\n      <td>approve</td>\n      <td>...</td>\n      <td>visits</td>\n      <td>person</td>\n      <td>property</td>\n      <td>uncredited</td>\n      <td>amusement</td>\n      <td>hearing</td>\n      <td>cedric</td>\n      <td>thief</td>\n      <td>bar</td>\n      <td>joe</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for top 1000 words ranked for every cluster\n",
    "cluster_words_ranked = pd.DataFrame()\n",
    "\n",
    "for i in range(len(cluster_words)):\n",
    "    cluster_words_ranked[f'{i}'] = cluster_words[i][0][0][:1000]\n",
    "    \n",
    "cluster_words_ranked"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:59:31.812204Z",
     "start_time": "2023-11-07T15:59:31.600599Z"
    }
   },
   "id": "a41d7d837d72e0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "cluster_words_ranked.to_csv('cluster_words.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T15:59:34.064003Z",
     "start_time": "2023-11-07T15:59:33.996034Z"
    }
   },
   "id": "56bbdec4dab76738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rating"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b1adbc63efef7d5"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0  Wikipedia Movie ID Freebase Movie ID  \\\n0               0              975900         /m/03vyhn   \n1               1             3196793         /m/08yl5d   \n2               2            28463795        /m/0crgdbh   \n3               3             9363483        /m/0285_cd   \n4               4              261236         /m/01mrr1   \n...           ...                 ...               ...   \n81736       81736            35228177        /m/0j7hxnt   \n81737       81737            34980460        /m/0g4pl34   \n81738       81738             9971909        /m/02pygw1   \n81739       81739              913762         /m/03pcrp   \n81740       81740            12476867        /m/02w7zz8   \n\n                                              Movie name Movie release date  \\\n0                                         Ghosts of Mars         2001-08-24   \n1      Getting Away with Murder: The JonBenét Ramsey ...         2000-02-16   \n2                                            Brun bitter               1988   \n3                                       White Of The Eye               1987   \n4                                      A Woman in Flames               1983   \n...                                                  ...                ...   \n81736                           Mermaids: The Body Found         2011-03-19   \n81737                                            Knuckle         2011-01-21   \n81738                                  Another Nice Mess         1972-09-22   \n81739  The Super Dimension Fortress Macross II: Lover...         1992-05-21   \n81740                                            Spliced               2002   \n\n       Movie box office revenue  Movie runtime  \\\n0                    14010832.0           98.0   \n1                           NaN           95.0   \n2                           NaN           83.0   \n3                           NaN          110.0   \n4                           NaN          106.0   \n...                         ...            ...   \n81736                       NaN          120.0   \n81737                       NaN           96.0   \n81738                       NaN           66.0   \n81739                       NaN          150.0   \n81740                       NaN           86.0   \n\n                          Movie languages  \\\n0      {\"/m/02h40lc\": \"English Language\"}   \n1      {\"/m/02h40lc\": \"English Language\"}   \n2      {\"/m/05f_3\": \"Norwegian Language\"}   \n3      {\"/m/02h40lc\": \"English Language\"}   \n4       {\"/m/04306rv\": \"German Language\"}   \n...                                   ...   \n81736  {\"/m/02h40lc\": \"English Language\"}   \n81737  {\"/m/02h40lc\": \"English Language\"}   \n81738  {\"/m/02h40lc\": \"English Language\"}   \n81739   {\"/m/03_9r\": \"Japanese Language\"}   \n81740  {\"/m/02h40lc\": \"English Language\"}   \n\n                                         Movie countries  \\\n0              {\"/m/09c7w0\": \"United States of America\"}   \n1              {\"/m/09c7w0\": \"United States of America\"}   \n2                                 {\"/m/05b4w\": \"Norway\"}   \n3                         {\"/m/07ssc\": \"United Kingdom\"}   \n4                                {\"/m/0345h\": \"Germany\"}   \n...                                                  ...   \n81736          {\"/m/09c7w0\": \"United States of America\"}   \n81737  {\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...   \n81738          {\"/m/09c7w0\": \"United States of America\"}   \n81739                              {\"/m/03_3d\": \"Japan\"}   \n81740                            {\"/m/0d060g\": \"Canada\"}   \n\n                                            Movie genres   TMDB_id  \\\n0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...   10016.0   \n1      {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  784579.0   \n2      {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  396302.0   \n3      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...   33592.0   \n4                                {\"/m/07s9rl0\": \"Drama\"}   11192.0   \n...                                                  ...       ...   \n81736                            {\"/m/07s9rl0\": \"Drama\"}  117124.0   \n81737  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...   44946.0   \n81738       {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  285337.0   \n81739  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...       NaN   \n81740  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  344309.0   \n\n      TMDB_original_language  \\\n0                         en   \n1                         en   \n2                         no   \n3                         en   \n4                         de   \n...                      ...   \n81736                     en   \n81737                     en   \n81738                     en   \n81739                    NaN   \n81740                     en   \n\n                                     TMDB_original_title  \\\n0                                         Ghosts of Mars   \n1      Getting Away with Murder: The JonBenét Ramsey ...   \n2                                            Brun bitter   \n3                                       White of the Eye   \n4                                    Die flambierte Frau   \n...                                                  ...   \n81736                           Mermaids: The Body Found   \n81737                                        Knucklehead   \n81738                                  Another Nice Mess   \n81739                                                NaN   \n81740                                     Nearly Spliced   \n\n                                           TMDB_overview  TMDB_popularity  \\\n0      In 2176, a Martian police unit is sent to pick...           17.280   \n1      Dramatization of the story behind the murder o...            0.750   \n2      A stolen bicycle case ends with drunken detect...            0.600   \n3      In a wealthy and isolated desert community, a ...            7.336   \n4      Eva, an upper-class housewife, frustratedly le...            2.397   \n...                                                  ...              ...   \n81736  A story that imagines how these real-world phe...            5.098   \n81737  A fight promoter deeply in debt to his crooked...            9.789   \n81738        Nixon and Agnew played as Laurel and Hardy.            1.960   \n81739                                                NaN              NaN   \n81740  Leon Errol is a befuddled bridegroom about to ...            0.949   \n\n      TMDB_release_date                                         TMDB_title  \\\n0            2001-08-24                                     Ghosts of Mars   \n1            2000-02-16  Getting Away with Murder: The JonBenét Ramsey ...   \n2            1988-11-17                                    Hair of the Dog   \n3            1987-06-19                                   White of the Eye   \n4            1983-05-11                                  A Woman in Flames   \n...                 ...                                                ...   \n81736        2011-03-19                           Mermaids: The Body Found   \n81737        2010-10-22                                        Knucklehead   \n81738        1972-08-23                                  Another Nice Mess   \n81739               NaN                                                NaN   \n81740        1921-06-11                                     Nearly Spliced   \n\n       TMDB_vote_average  TMDB_vote_count  \n0                  5.123            980.0  \n1                  8.000              1.0  \n2                  0.000              0.0  \n3                  5.742             64.0  \n4                  5.300             13.0  \n...                  ...              ...  \n81736              4.500             20.0  \n81737              5.500             50.0  \n81738              0.000              0.0  \n81739                NaN              NaN  \n81740              6.000              1.0  \n\n[81741 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Wikipedia Movie ID</th>\n      <th>Freebase Movie ID</th>\n      <th>Movie name</th>\n      <th>Movie release date</th>\n      <th>Movie box office revenue</th>\n      <th>Movie runtime</th>\n      <th>Movie languages</th>\n      <th>Movie countries</th>\n      <th>Movie genres</th>\n      <th>TMDB_id</th>\n      <th>TMDB_original_language</th>\n      <th>TMDB_original_title</th>\n      <th>TMDB_overview</th>\n      <th>TMDB_popularity</th>\n      <th>TMDB_release_date</th>\n      <th>TMDB_title</th>\n      <th>TMDB_vote_average</th>\n      <th>TMDB_vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>975900</td>\n      <td>/m/03vyhn</td>\n      <td>Ghosts of Mars</td>\n      <td>2001-08-24</td>\n      <td>14010832.0</td>\n      <td>98.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n      <td>10016.0</td>\n      <td>en</td>\n      <td>Ghosts of Mars</td>\n      <td>In 2176, a Martian police unit is sent to pick...</td>\n      <td>17.280</td>\n      <td>2001-08-24</td>\n      <td>Ghosts of Mars</td>\n      <td>5.123</td>\n      <td>980.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3196793</td>\n      <td>/m/08yl5d</td>\n      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n      <td>2000-02-16</td>\n      <td>NaN</td>\n      <td>95.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n      <td>784579.0</td>\n      <td>en</td>\n      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n      <td>Dramatization of the story behind the murder o...</td>\n      <td>0.750</td>\n      <td>2000-02-16</td>\n      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n      <td>8.000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>28463795</td>\n      <td>/m/0crgdbh</td>\n      <td>Brun bitter</td>\n      <td>1988</td>\n      <td>NaN</td>\n      <td>83.0</td>\n      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n      <td>{\"/m/05b4w\": \"Norway\"}</td>\n      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n      <td>396302.0</td>\n      <td>no</td>\n      <td>Brun bitter</td>\n      <td>A stolen bicycle case ends with drunken detect...</td>\n      <td>0.600</td>\n      <td>1988-11-17</td>\n      <td>Hair of the Dog</td>\n      <td>0.000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>9363483</td>\n      <td>/m/0285_cd</td>\n      <td>White Of The Eye</td>\n      <td>1987</td>\n      <td>NaN</td>\n      <td>110.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n      <td>33592.0</td>\n      <td>en</td>\n      <td>White of the Eye</td>\n      <td>In a wealthy and isolated desert community, a ...</td>\n      <td>7.336</td>\n      <td>1987-06-19</td>\n      <td>White of the Eye</td>\n      <td>5.742</td>\n      <td>64.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>261236</td>\n      <td>/m/01mrr1</td>\n      <td>A Woman in Flames</td>\n      <td>1983</td>\n      <td>NaN</td>\n      <td>106.0</td>\n      <td>{\"/m/04306rv\": \"German Language\"}</td>\n      <td>{\"/m/0345h\": \"Germany\"}</td>\n      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n      <td>11192.0</td>\n      <td>de</td>\n      <td>Die flambierte Frau</td>\n      <td>Eva, an upper-class housewife, frustratedly le...</td>\n      <td>2.397</td>\n      <td>1983-05-11</td>\n      <td>A Woman in Flames</td>\n      <td>5.300</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>81736</th>\n      <td>81736</td>\n      <td>35228177</td>\n      <td>/m/0j7hxnt</td>\n      <td>Mermaids: The Body Found</td>\n      <td>2011-03-19</td>\n      <td>NaN</td>\n      <td>120.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n      <td>117124.0</td>\n      <td>en</td>\n      <td>Mermaids: The Body Found</td>\n      <td>A story that imagines how these real-world phe...</td>\n      <td>5.098</td>\n      <td>2011-03-19</td>\n      <td>Mermaids: The Body Found</td>\n      <td>4.500</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>81737</th>\n      <td>81737</td>\n      <td>34980460</td>\n      <td>/m/0g4pl34</td>\n      <td>Knuckle</td>\n      <td>2011-01-21</td>\n      <td>NaN</td>\n      <td>96.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...</td>\n      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n      <td>44946.0</td>\n      <td>en</td>\n      <td>Knucklehead</td>\n      <td>A fight promoter deeply in debt to his crooked...</td>\n      <td>9.789</td>\n      <td>2010-10-22</td>\n      <td>Knucklehead</td>\n      <td>5.500</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>81738</th>\n      <td>81738</td>\n      <td>9971909</td>\n      <td>/m/02pygw1</td>\n      <td>Another Nice Mess</td>\n      <td>1972-09-22</td>\n      <td>NaN</td>\n      <td>66.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n      <td>285337.0</td>\n      <td>en</td>\n      <td>Another Nice Mess</td>\n      <td>Nixon and Agnew played as Laurel and Hardy.</td>\n      <td>1.960</td>\n      <td>1972-08-23</td>\n      <td>Another Nice Mess</td>\n      <td>0.000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>81739</th>\n      <td>81739</td>\n      <td>913762</td>\n      <td>/m/03pcrp</td>\n      <td>The Super Dimension Fortress Macross II: Lover...</td>\n      <td>1992-05-21</td>\n      <td>NaN</td>\n      <td>150.0</td>\n      <td>{\"/m/03_9r\": \"Japanese Language\"}</td>\n      <td>{\"/m/03_3d\": \"Japan\"}</td>\n      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81740</th>\n      <td>81740</td>\n      <td>12476867</td>\n      <td>/m/02w7zz8</td>\n      <td>Spliced</td>\n      <td>2002</td>\n      <td>NaN</td>\n      <td>86.0</td>\n      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n      <td>{\"/m/0d060g\": \"Canada\"}</td>\n      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n      <td>344309.0</td>\n      <td>en</td>\n      <td>Nearly Spliced</td>\n      <td>Leon Errol is a befuddled bridegroom about to ...</td>\n      <td>0.949</td>\n      <td>1921-06-11</td>\n      <td>Nearly Spliced</td>\n      <td>6.000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>81741 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cluster_labels from a file\n",
    "with open('movie_clusters_id.pkl', 'rb') as f:\n",
    "    movie_clusters_id = pickle.load(f)\n",
    "    \n",
    "# Load cluster_df from a file\n",
    "TMDB = pd.read_csv('data/movie_metadata_TMDB.csv')\n",
    "TMDB"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:58.397692Z",
     "start_time": "2023-11-08T11:41:55.472157Z"
    }
   },
   "id": "77dad066489db9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "0        5.123\n1        8.000\n2        0.000\n3        5.742\n4        5.300\n         ...  \n81736    4.500\n81737    5.500\n81738    0.000\n81739      NaN\n81740    6.000\nName: TMDB_vote_average, Length: 81741, dtype: float64"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings_cleand = TMDB['TMDB_vote_average']\n",
    "movie_ratings_cleand"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:54:26.368094Z",
     "start_time": "2023-11-08T11:54:26.343283Z"
    }
   },
   "id": "d363bdd75618aafd"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "{9: 2215,\n 8: 9340,\n 74: 4716,\n 85: 191,\n 70: 104,\n 3: 865,\n 27: 275,\n 34: 82,\n 12: 2088,\n 75: 1183,\n 0: 174,\n 25: 1219,\n 86: 90,\n 39: 223,\n 33: 141,\n 96: 168,\n 32: 91,\n 29: 91,\n 18: 87,\n 59: 399,\n 84: 201,\n 67: 124,\n 83: 95,\n 36: 596,\n 37: 125,\n 56: 127,\n 58: 119,\n 23: 1122,\n 42: 262,\n 19: 126,\n 44: 923,\n 53: 723,\n 14: 785,\n 73: 91,\n 93: 77,\n 43: 208,\n 76: 148,\n 69: 454,\n 97: 101,\n 6: 691,\n 22: 137,\n 72: 476,\n 49: 78,\n 15: 665,\n 99: 265,\n 94: 995,\n 48: 266,\n 47: 158,\n 2: 163,\n 24: 655,\n 66: 214,\n 13: 205,\n 60: 184,\n 5: 467,\n 65: 307,\n 21: 205,\n 28: 275,\n 87: 189,\n 95: 60,\n 63: 121,\n 98: 107,\n 64: 273,\n 45: 102,\n 31: 243,\n 50: 159,\n 61: 91,\n 92: 187,\n 20: 223,\n 89: 426,\n 79: 106,\n 80: 64,\n 46: 205,\n 62: 244,\n 51: 98,\n 7: 138,\n 40: 111,\n 78: 104,\n 68: 60,\n 55: 144,\n 41: 145,\n 82: 70,\n 4: 106,\n 17: 102,\n 11: 139,\n 91: 142,\n 16: 108,\n 88: 155,\n 52: 149,\n 71: 189,\n 54: 65,\n 77: 102,\n 35: 95,\n 1: 58,\n 38: 83,\n 90: 96,\n 81: 122,\n 57: 146,\n 26: 107,\n 30: 33,\n 10: 84}"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_counts = {}\n",
    "\n",
    "for cluster_label in movie_clusters.values():\n",
    "    cluster_counts[cluster_label] = cluster_counts.get(cluster_label, 0) + 1\n",
    "\n",
    "cluster_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:49:34.662734Z",
     "start_time": "2023-11-08T11:49:33.762615Z"
    }
   },
   "id": "fba2c24132a981dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_rating_df = "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "574bac491fea7e2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NPL version (Nothing yet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "157e33cc2b984c4a"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Load summaries_preprocessed_dist from a JSON file\n",
    "with open('summaries_preprocessed_dist.json', 'r') as f:\n",
    "    summaries_preprocessed_dist = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:11:39.091150Z",
     "start_time": "2023-11-06T16:11:38.911288Z"
    }
   },
   "id": "e50c55d094624b6c"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T15:50:38.847465Z",
     "start_time": "2023-11-06T15:50:38.263592Z"
    }
   },
   "id": "10b04b346fe708ad"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T15:51:12.353947Z",
     "start_time": "2023-11-06T15:51:12.322750Z"
    }
   },
   "id": "7b8fa341c2ad36bb"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[86], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenized_sum \u001B[38;5;241m=\u001B[39m \u001B[43msummaries_dist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m(preprocess_function, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "tokenized_sum = summaries_preprocessed_dist.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:12:47.846330Z",
     "start_time": "2023-11-06T16:12:47.610183Z"
    }
   },
   "id": "c2f8516f8486b447"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2a68eabba0f92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8250491b32c6139"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Enriching data\n",
    "#### 1. Adding data from www.themoviedb.org (TMDB)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7379b1837565ccec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we are going to be using the API of www.themoviedb.org (TMDB) to populate the existing dataframe with more information about the movie. The script is going to query the website with the movie name and match with the movie, where the release date is the closest. If no match is found the code skips the movie and goes to the next.\n",
    "\n",
    "This 1. step is most importantly adding the TMDB_ID which is a unique identifier for the movie which can be used to further enrich the data.\n",
    "\n",
    "This script was run separately in another file in /scratch/add_TMDB_movie_metadata.py as it needed to be run several times since the API was limited by 40 requests/s.\n",
    " \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a14b26427b680f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36108f48bc9b153"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/movie.metadata.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 13\u001B[0m\n\u001B[0;32m      8\u001B[0m load_dotenv() \u001B[38;5;66;03m# Loads .env files aka. the TMDB_API_KEY\u001B[39;00m\n\u001B[0;32m     10\u001B[0m headers_movie_metadata \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWikipedia Movie ID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFreebase Movie ID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie release date\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     11\u001B[0m                           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie box office revenue\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie runtime\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie languages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie countries\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     12\u001B[0m                           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie genres\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m---> 13\u001B[0m movie_metadata \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/data/movie.metadata.tsv\u001B[39m\u001B[38;5;124m'\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, names\u001B[38;5;241m=\u001B[39mheaders_movie_metadata)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Load API key\u001B[39;00m\n\u001B[0;32m     17\u001B[0m TMDB_API_KEY \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTMDB_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m   1662\u001B[0m     f,\n\u001B[0;32m   1663\u001B[0m     mode,\n\u001B[0;32m   1664\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1665\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1666\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   1667\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[0;32m   1668\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1669\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1670\u001B[0m )\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    860\u001B[0m             handle,\n\u001B[0;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    865\u001B[0m         )\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/data/movie.metadata.tsv'"
     ]
    }
   ],
   "source": [
    "import tmdbsimple as tmdb # Wrapper library for the API of themoviedb.org  (TMDB)\n",
    "from tqdm import tqdm # Progress bar for the script\n",
    "import pandas as pd\n",
    "from datetime import datetime # Used for comparing movie release dates\n",
    "from dotenv import load_dotenv # Makes keeping the API-key as local environment file simpler\n",
    "import os # Used for loading the .env file\n",
    "\n",
    "load_dotenv() # Loads .env files aka. the TMDB_API_KEY\n",
    "\n",
    "headers_movie_metadata = [\"Wikipedia Movie ID\", \"Freebase Movie ID\", \"Movie name\", \"Movie release date\",\n",
    "                          \"Movie box office revenue\", \"Movie runtime\", \"Movie languages\", \"Movie countries\",\n",
    "                          \"Movie genres\"]\n",
    "movie_metadata = pd.read_csv('/data/movie.metadata.tsv', sep=\"\\t\", names=headers_movie_metadata)\n",
    "\n",
    "\n",
    "# Load API key\n",
    "TMDB_API_KEY = os.environ.get(\"TMDB_API_KEY\")\n",
    "tmdb.API_KEY = TMDB_API_KEY\n",
    "tmdb.REQUESTS_TIMEOUT = 5  # Seconds, for both connect and read\n",
    "\n",
    "# Create a list to save progress\n",
    "saved_progress = []\n",
    "\n",
    "# Determine where to resume\n",
    "start_index = 28000\n",
    "\n",
    "# Progress file that can be used to resume\n",
    "#saved_progress = pd.read_json('progress.json')['index'].tolist()\n",
    "#start_index = saved_progress[-1] + 1  # Start from the next index\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "movie_metadata_TMDB = movie_metadata.copy()\n",
    "\n",
    "for index, row in tqdm(movie_metadata_TMDB.iterrows(), total=len(movie_metadata_TMDB), desc=\"Processing\"): # Wraps for loop in progress bar.\n",
    "    \n",
    "    # Skip previously processed indices - Commented out in favor of manual start_index\n",
    "    #if index in saved_progress:\n",
    "    #    continue\n",
    "    if index < start_index:\n",
    "        continue\n",
    "    try:\n",
    "        if not pd.isna(row[\"Movie release date\"]):\n",
    "            search = tmdb.Search()\n",
    "            response = search.movie(query=row[\"Movie name\"])\n",
    "\n",
    "            # Convert dataframe release date to datetime\n",
    "            movie_release_date_str = row[\"Movie release date\"]\n",
    "            if len(movie_release_date_str) == 4:  # Handle \"YYYY\" format\n",
    "                movie_release_date = datetime.strptime(movie_release_date_str, \"%Y\").date()\n",
    "            elif len(movie_release_date_str) == 7:  # Handle \"YYYY-DD\" format\n",
    "                movie_release_date = datetime.strptime(movie_release_date_str, \"%Y-%m\").date()\n",
    "            else:  # Assume it's in the format \"YYYY-MM-DD\"\n",
    "                movie_release_date = datetime.strptime(movie_release_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "            # Handle if release_date is empty.\n",
    "            date_list_converted = [datetime.strptime(each_date['release_date'], \"%Y-%m-%d\").date() for each_date in\n",
    "                                   search.results if each_date.get('release_date')]\n",
    "\n",
    "            # Create list of differences in time\n",
    "            differences = [abs(movie_release_date - each_date) for each_date in date_list_converted]\n",
    "            \n",
    "            # If differences are empty = skip\n",
    "            if not differences:\n",
    "                continue\n",
    "            minimum_index = differences.index(min(differences))  # Index of the closest match\n",
    "            match = search.results[minimum_index]\n",
    "            # print(f\"Closest match: {match['title']} (Release Date: {match['release_date']})\")\n",
    "\n",
    "            # Add info in dataframe about the movie\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_id'] = match['id']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_original_language'] = match['original_language']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_original_title'] = match['original_title']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_overview'] = match['overview']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_popularity'] = match['popularity']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_release_date'] = match['release_date']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_title'] = match['title']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_vote_average'] = match['vote_average']\n",
    "            movie_metadata_TMDB.loc[index, 'TMDB_vote_count'] = match['vote_count']\n",
    "            \n",
    "            # Save the index as progress\n",
    "            saved_progress.append(index)\n",
    "\n",
    "            # Save progress periodically (in case of interruption)\n",
    "            if index % 50 == 0:\n",
    "                progress_df = pd.DataFrame({'index': saved_progress})\n",
    "                progress_df.to_json('progress.json')\n",
    "                movie_metadata_TMDB.to_csv('movie_metadata_TMDB.csv', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {index}: {str(e)}\")\n",
    "\n",
    "# Save final progress\n",
    "progress_df = pd.DataFrame({'index': saved_progress})\n",
    "progress_df.to_json('progress.json')\n",
    "\n",
    "# Save your final DataFrame\n",
    "movie_metadata_TMDB.to_csv('modified_data/movie_metadata_TMDB.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "386c21ad8d1087f6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added TMDB ID to 68944 movies. Total movies: 81741. \n",
      " Percentage populated: 84.34%\n"
     ]
    }
   ],
   "source": [
    "# Comparing how many rows were populated in the enriching.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('modified_data/movie_metadata_TMDB.csv')\n",
    "print(f\"Added TMDB ID to {df['TMDB_id'].count()} movies. Total movies: {df['Wikipedia Movie ID'].count()}. \\n Percentage populated: {round(df['TMDB_id'].count()/df['Wikipedia Movie ID'].count()*100,2)}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7989e2337cadbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Adding Movie Revenue\n",
    "Many of the movies are missing their revenue and TMDB has that information.\n",
    "E.g.: https://www.themoviedb.org/movie/51284"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20ce707a4597922b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bc6aaafef8edb0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
